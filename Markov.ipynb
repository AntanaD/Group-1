{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import ast\n",
    "import operator\n",
    "from textblob import TextBlob\n",
    "from textblob.np_extractors import ConllExtractor\n",
    "from textblob.taggers import NLTKTagger\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer=SnowballStemmer(\"english\")\n",
    "\n",
    "mat=pd.read_csv('mat.txt', sep = '\\t')\n",
    "\n",
    "with open('content_comments_data.json') as data_file:    \n",
    "    dataset = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#удаление 1 слова\n",
    "def retract_words(data):\n",
    "    for w in words1['Words']:\n",
    "        for comm in data['Comms']:\n",
    "            for i, word in enumerate(comm):\n",
    "                if (comm[i]==w):\n",
    "                    del comm[i]\n",
    "                if (re.search(r'[^\\w*\\.\\,\\'\\0-9\\!\\:\\;\\?\\-\\\\\\/\\\"]', word)): \n",
    "                    del comm[i]\n",
    "                else:\n",
    "                    continue\n",
    "    return data\n",
    "\n",
    "#удаление сочетания из 2 слов\n",
    "def retract_two_words(data):\n",
    "    for w in words2['Words']:\n",
    "        for comm in data['Comms']:\n",
    "            for i, word in enumerate(comm):\n",
    "                    if i>0:\n",
    "                        if ((comm[i].join(comm[i-1]))==w):\n",
    "                            del comm[i]\n",
    "                            del comm[i-1]\n",
    "    return data\n",
    "\n",
    "#удаление сочетания из 3 слов\n",
    "def retract_three_words(data):\n",
    "    for w in words3['Words']:\n",
    "        for comm in data['Comms']:\n",
    "            for i, word in enumerate(comm):\n",
    "                    if i>1:\n",
    "                        if (comm[i].join(comm[i-1])).join(comm[i-2])==w:\n",
    "                            del comm[i]\n",
    "                            del comm[i-1]\n",
    "                            del comm[i-2]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_popular(dataset, Ind):   \n",
    "    #запись комментариев\n",
    "    comme, real, name = [], [], []\n",
    "    for i in range(len(dataset[Ind]['comments'])):\n",
    "        comme.append(dataset[Ind]['comments'][i]['text'])\n",
    "    data=pd.DataFrame()\n",
    "    data['Comments']=comme\n",
    "    for comm in data.Comments:\n",
    "        comm=TextBlob(comm)\n",
    "        real.append((' '.join(comm.words.lower()).split()))\n",
    "    data['Comms']=real\n",
    "    \n",
    "    #удаление \"лишнего\"\n",
    "    data=retract_words(data)\n",
    "    data=retract_two_words(data)\n",
    "    data=retract_three_words(data)\n",
    "    \n",
    "    #словарь частот\n",
    "    words_dict = dict()\n",
    "    for i in range(data.shape[1]):\n",
    "        for comm in data['Comms']:\n",
    "                for i, word in enumerate(comm):\n",
    "                    if word not in words_dict:\n",
    "                        words_dict[word] = 0\n",
    "                    else:\n",
    "                        words_dict[word] += 1\n",
    "    stems=[]\n",
    "    words_dict1=words_dict.copy()\n",
    "\n",
    "    for word in words_dict1:\n",
    "        x=stemmer.stem(word.decode('utf-8'))\n",
    "        if x in stems:\n",
    "            del words_dict[word]\n",
    "        else: \n",
    "            stems.append(x)\n",
    "    \n",
    "    #поиск самых частых слов (4 глубины)\n",
    "    maxim, maxim1, maxim2, maxim3 = 0, 0, 0, 0\n",
    "    for k in words_dict.values():\n",
    "        if (k>maxim):\n",
    "            maxim=k\n",
    "    for k in words_dict.values():\n",
    "        if (k>maxim1)&(k!=maxim):\n",
    "            maxim1=k\n",
    "\n",
    "    for k in words_dict.items():\n",
    "        if ((k[1]==maxim)|(k[1]==maxim1))&(k[1]!=1):\n",
    "            name.append(k[0])\n",
    "\n",
    "    if len(name)<6:\n",
    "        for k in words_dict.values():\n",
    "            if (k>maxim2)&(k!=maxim)&(k!=maxim1):\n",
    "                maxim2=k\n",
    "        for k in words_dict.items():\n",
    "            if (k[1]==maxim2)&(k[1]!=1):\n",
    "                name.append(k[0])\n",
    "\n",
    "    if len(name)<6:\n",
    "        for k in words_dict.values():\n",
    "            if (k>maxim3)&(k!=maxim)&(k!=maxim1)&(k!=maxim2):\n",
    "                maxim3=k\n",
    "        for k in words_dict.items():\n",
    "            if (k[1]==maxim3)&(k[1]!=1):\n",
    "                name.append(k[0])\n",
    "    \n",
    "    result, url = [], []\n",
    "    result.append(name)\n",
    "    memes=pd.DataFrame()\n",
    "    url.append(dataset[Ind]['url'])\n",
    "    memes['Url']=url\n",
    "    memes['Frequent']=result\n",
    "    \n",
    "    return memes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Url</th>\n",
       "      <th>Frequent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://img.ifcdn.com/images/b136b806781c3480c8...</td>\n",
       "      <td>[right, guess, take, phasma]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://img.ifcdn.com/images/62ee7d15b1ff253e52...</td>\n",
       "      <td>[elmo, back, looks, milk, black, rich, store, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://img.ifcdn.com/videos/337c7a1f2265c2ad1c...</td>\n",
       "      <td>[tears, male, get, cry, women, feminists, men,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://img.ifcdn.com/images/e39eea7eb4dc0f0320...</td>\n",
       "      <td>[money, smart, everyone, eagles, need, play]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://img.ifcdn.com/images/1917b8fb8c20fd464f...</td>\n",
       "      <td>[good, get, girl, first, top, girlfriend]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Url  \\\n",
       "0  http://img.ifcdn.com/images/b136b806781c3480c8...   \n",
       "0  http://img.ifcdn.com/images/62ee7d15b1ff253e52...   \n",
       "0  http://img.ifcdn.com/videos/337c7a1f2265c2ad1c...   \n",
       "0  http://img.ifcdn.com/images/e39eea7eb4dc0f0320...   \n",
       "0  http://img.ifcdn.com/images/1917b8fb8c20fd464f...   \n",
       "\n",
       "                                            Frequent  \n",
       "0                       [right, guess, take, phasma]  \n",
       "0  [elmo, back, looks, milk, black, rich, store, ...  \n",
       "0  [tears, male, get, cry, women, feminists, men,...  \n",
       "0       [money, smart, everyone, eagles, need, play]  \n",
       "0          [good, get, girl, first, top, girlfriend]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent=pd.DataFrame(columns=('Url', 'Frequent'))\n",
    "for i in range(len(dataset)):\n",
    "    frequent=frequent.append(search_popular(dataset, i))\n",
    "frequent.to_pickle('frequent.p')\n",
    "frequent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "coms, comme, real_coms, real_comme, real, url, all_com = [], [], [], [], [], [], []\n",
    "  \n",
    "for Ind in range(len(dataset)):\n",
    "    print Ind\n",
    "    url.append(dataset[Ind]['url'])\n",
    "    for i in range(len(dataset[Ind]['comments'])):\n",
    "        real_comme.append(dataset[Ind]['comments'][i]['text'])\n",
    "        com=TextBlob(dataset[Ind]['comments'][i]['text']).correct()\n",
    "        comme.append(''.join(com.lower()))\n",
    "        all_com.append(''.join(com.lower()))\n",
    "    coms.append(comme)\n",
    "    real_coms.append(real_comme)\n",
    "    comme=[]\n",
    "    real_comme=[]\n",
    "data=pd.DataFrame(columns=('Url', 'Comments', 'Good Comments', 'Words', 'Normal Words'))\n",
    "data['Url']=url\n",
    "data['Comments']=real_coms\n",
    "data['Good Comments']=coms\n",
    "\n",
    "for Ind in range(len(data)):\n",
    "    for comm in data.Comments[Ind]:\n",
    "        comm=TextBlob(comm)\n",
    "        if comm not in real: real.append((' '.join(comm.words.lower())))\n",
    "    data['Words'][Ind]=real\n",
    "    real=[]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Url</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Normal Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://img.ifcdn.com/images/b136b806781c3480c8...</td>\n",
       "      <td>[Oh and Phasma dies, Is the humor corny or pol...</td>\n",
       "      <td>[oh, and, phasma, dies, is, the, humor, corny,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://img.ifcdn.com/images/62ee7d15b1ff253e52...</td>\n",
       "      <td>[In prison, He just got back from the store, W...</td>\n",
       "      <td>[in, prison, he, just, got, back, from, the, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://img.ifcdn.com/videos/337c7a1f2265c2ad1c...</td>\n",
       "      <td>[Fukin rekt, Baby batter, Featureworthy, More ...</td>\n",
       "      <td>[rekt, baby, batter, featureworthy, more, proo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://img.ifcdn.com/images/e39eea7eb4dc0f0320...</td>\n",
       "      <td>[How are you going to contact everyone?, Is th...</td>\n",
       "      <td>[how, are, you, going, to, contact, everyone, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://img.ifcdn.com/images/1917b8fb8c20fd464f...</td>\n",
       "      <td>[Spoken like a true virgin, Yeah I did that an...</td>\n",
       "      <td>[spoken, like, a, true, virgin, yeah, i, did, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Url  \\\n",
       "0  http://img.ifcdn.com/images/b136b806781c3480c8...   \n",
       "1  http://img.ifcdn.com/images/62ee7d15b1ff253e52...   \n",
       "2  http://img.ifcdn.com/videos/337c7a1f2265c2ad1c...   \n",
       "3  http://img.ifcdn.com/images/e39eea7eb4dc0f0320...   \n",
       "4  http://img.ifcdn.com/images/1917b8fb8c20fd464f...   \n",
       "\n",
       "                                            Comments  \\\n",
       "0  [Oh and Phasma dies, Is the humor corny or pol...   \n",
       "1  [In prison, He just got back from the store, W...   \n",
       "2  [Fukin rekt, Baby batter, Featureworthy, More ...   \n",
       "3  [How are you going to contact everyone?, Is th...   \n",
       "4  [Spoken like a true virgin, Yeah I did that an...   \n",
       "\n",
       "                                        Normal Words  \n",
       "0  [oh, and, phasma, dies, is, the, humor, corny,...  \n",
       "1  [in, prison, he, just, got, back, from, the, s...  \n",
       "2  [rekt, baby, batter, featureworthy, more, proo...  \n",
       "3  [how, are, you, going, to, contact, everyone, ...  \n",
       "4  [spoken, like, a, true, virgin, yeah, i, did, ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, wrds = [], []\n",
    "mats=list(mat['Words'])\n",
    "for Ind in range(len(data)):\n",
    "    for sent in data['Words'][Ind]:\n",
    "        for i, comm in enumerate(re.split(r'\\s+', sent)):\n",
    "            if comm not in wrds:\n",
    "                if comm not in mats: \n",
    "                    wrds.append(comm)\n",
    "    data['Normal Words'][Ind]=wrds\n",
    "    wrds=[]  \n",
    "del data['Words']\n",
    "data.to_pickle('normal_words.p')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
